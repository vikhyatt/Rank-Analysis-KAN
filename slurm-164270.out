wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: zeusisgreat (zeusisgreat-indian-institute-of-technology-bombay). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /home/vagrawal/Rank-Analysis-KAN/wandb/run-20241010_115033-lyic30sj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kan_mixer_imgnet_adam_cosine_aa_cm
wandb: ‚≠êÔ∏è View project at https://wandb.ai/zeusisgreat-indian-institute-of-technology-bombay/mlp_mixer
wandb: üöÄ View run at https://wandb.ai/zeusisgreat-indian-institute-of-technology-bombay/mlp_mixer/runs/lyic30sj
/home/vagrawal/venvs/kan/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
/home/vagrawal/venvs/kan/lib64/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 6, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Device using: cuda
Polynomial Basis: False, Degree of Polynomial: 2, Using Same Function: False, Using same weights: False, Positional Embeddings: False, CPD Decomposition: False, Softmax Prod: False, Init: uniform
Number of Learnable Parameters: 8688676
0it [00:00, ?it/s]1it [00:15, 15.54s/it]/var/spool/slurmd/job164270/slurm_script: line 14: 3429106 Killed                  python main.py --init 'uniform' --init-scale 0.02 --dataset imgnet --model kan_mixer --autoaugment --epochs 600 --eval-batch-size 256 --num-workers 12 --cutmix-prob 0.5 --patch-size 8 --hidden-c 512 --hidden-s 64 --hidden-size 128 --batch-size 256 --num-layers 4 --skip-min 1.0 --checkpoint-epoch 0
slurmstepd: error: Detected 1 oom_kill event in StepId=164270.batch. Some of the step tasks have been OOM Killed.
